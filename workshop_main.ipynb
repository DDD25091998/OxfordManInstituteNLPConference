{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ae4cd8",
   "metadata": {},
   "source": [
    "# Oxford Man Institute NLP Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d7c68",
   "metadata": {},
   "source": [
    "## 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e5b5a0",
   "metadata": {},
   "source": [
    "There are several ways of performing sentiment classification on a document or article, ranging from word-counts to modern Transformer-based Language Models. In this tutorial we will take you through a range of classification techniques:\n",
    "- Loughran & McDonald financial sentiment dictionary\n",
    "- Naive Bayes Classifier\n",
    "- BERT fine-tuned on general sentiment datasets\n",
    "    - BERT that has been trained on positive and negative financial documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029a21a-8149-4aa9-b726-2064e745b9ef",
   "metadata": {},
   "source": [
    "## 2. Load and analyse the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272fa01e",
   "metadata": {},
   "source": [
    "### Import packages and load dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c3d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import inspect\n",
    "import csv\n",
    "import operator\n",
    "from omi_nlp_tools import mutual_information # function to get mutual information \n",
    "# import my_functions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00663a-8d6a-4ea3-8b10-680d917b5183",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f05db8-fca7-4974-ac3f-bb685a89fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'data/kaggle_data.csv')\n",
    "# df.columns = ['text', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17b5ac4-3480-44c0-9083-4b9e4780e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drago\\AppData\\Local\\Temp\\ipykernel_22228\\2570486051.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('data\\\\FinancialPhraseBank-v1.0\\\\Sentences_50Agree.txt',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  According to Gran , the company has no plans t...   neutral\n",
       "1  Technopolis plans to develop in stages an area...   neutral\n",
       "2  The international electronic industry company ...  negative\n",
       "3  With the new production plant the company woul...  positive\n",
       "4  According to the company 's updated strategy f...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data\\\\FinancialPhraseBank-v1.0\\\\Sentences_50Agree.txt',\n",
    "            encoding = 'ISO-8859-1',on_bad_lines='skip',sep = '.@', names=['text', 'class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c750f-eee1-40a9-b6af-812ee7a1411b",
   "metadata": {},
   "source": [
    "#### What kind of text are we dealing with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656f863-165f-4af2-8d23-bbcc47ff1ca5",
   "metadata": {},
   "source": [
    "The Financial PhraseBank was used by Maks and Vossen (2014) in their paper ***\"Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts\"***. The authors scraped the LexisNexis database for news articles about companies on the OMX Helsinki database.\n",
    "\n",
    "Although very small, the dataset has since been widely used in the financial community to test and deploy domain specific language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa191de-e03f-48f7-a236-dcbd19b8ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest positive sentence is: \n",
      "\n",
      " 379    The Finnish supplier of BSS-OSS and VAS for telecom operators , Tecnotree , has received expansion orders worth a total US$ 7.3 mn for its convergent charging and next generation messaging solutions in Latin America , the company announced without specifying which operators had placed the orders \n",
      "Name: text, dtype: object \n",
      "\n",
      "\n",
      "The longest negative sentence is: \n",
      "\n",
      " 4652    Finnish Exel Composites , a technology company that designs , manufactures , and markets composite profiles and tubes for various industrial applications , reports its net sales decreased by 0.6 % in the second quarter of 2010 to EUR 19.2 mn from EUR 19.3 mn in the corresponding period in 2009 \n",
      "Name: text, dtype: object \n",
      "\n",
      "\n",
      "The longest neutral sentence is: \n",
      "\n",
      " 1863    Supported Nokia phones include : N96 , N95-8GB , N95 , N93-N931 , N92 , N85 , N82 , N81 , N80 , N79 , N78 , N77 , N76 , N75 , N73 , N72 , N71 , E90 , E71 , E70 , E66 , E65 , E62 , E61-E61i , E60 , E51 , E50 , Touch Xpress 5800 , 6220 Classic , 6210 Navigator , 6120 Classic , 6110 Navigator , 5700 , 5500 , 5320XM \n",
      "Name: text, dtype: object \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cata in ['positive','negative','neutral']:\n",
    "    cata_df = df[df['class'] == cata]\n",
    "    cata_lens = cata_df['text'].str.len()\n",
    "    max_sentence = cata_df[cata_lens == cata_lens.max()]\n",
    "    with pd.option_context('display.max_colwidth', 500):\n",
    "        print(f'The longest {cata} sentence is: \\n\\n', max_sentence['text'], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12bc77-18c8-400c-9ff8-cefcc2148b19",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26553ef6-a6e1-4dec-ba10-604704c86e41",
   "metadata": {},
   "source": [
    "The dataset we are using has already been cleaned as it is widely used in the field. If you are using your own custom dataset it may be necessary to clean the text of special characters, URLs, user mentions, emojis etc. \n",
    "\n",
    "We will add another columns to our dataset that contains a **tokenised version** of the text as this will form the basis of our Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e593fd5-367f-4b2b-8f88-b63858090acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "df[\"tokenised_text\"] = df.text.apply(lambda x: token_pattern.findall(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c1c79-7c2e-46c0-8e0b-88a30da01aef",
   "metadata": {},
   "source": [
    "**Remove the neutral category** so that we are left with a more extreme examples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2632802-7f69-4b93-ab2f-d412eaaa7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['class'] != 'neutral']\n",
    "categories = list(set(df['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448becfe-ea9c-475a-b61d-3e5c19b4c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967 entries in the dataset\n",
      "604 entries / 30.71% labelled as negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_negative = df[df['class']==\"negative\"].shape[0]\n",
    "prop_negative = df[df['class']==\"negative\"].shape[0]/df.shape[0]\n",
    "\n",
    "print(f\"{df.shape[0]} entries in the dataset\")\n",
    "print(\"{} entries / {:.2%} labelled as negative\\n\".format(n_negative, prop_negative)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a333bc-6838-4845-ab02-85018db8497a",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3dd591-1144-4487-aa06-44255170abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, dev_text, test_text = dict(), dict(), dict()\n",
    "\n",
    "for c_i in categories:\n",
    "    train_text[c_i], devtest_text = train_test_split(df[df['class']==c_i].tokenised_text,\n",
    "                                                         train_size=0.7, random_state=123)\n",
    "    dev_text[c_i], test_text[c_i] = train_test_split(devtest_text,\n",
    "                                                         train_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76f108-3939-4549-946b-d5bc2bc5ba9f",
   "metadata": {},
   "source": [
    "Create vocab dict and remove stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1ecb88-57f6-412d-9fe9-9308b163826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab dict\n",
    "vocab = defaultdict(Counter)\n",
    "n_text = defaultdict(Counter)\n",
    "\n",
    "# Create vocabularies\n",
    "for c_i in categories:\n",
    "    for text in train_text[c_i]:\n",
    "        vocab[c_i].update(text)\n",
    "        n_text[c_i].update(set(text))\n",
    "\n",
    "# Remove stopwords\n",
    "stopwords = list()\n",
    "\n",
    "with open('./data/stopwords.txt', 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in fd:\n",
    "        stopwords.append(row.replace(\"\\n\",\"\"))\n",
    "        \n",
    "for c_i in categories:\n",
    "    for sw in stopwords:\n",
    "        del vocab[c_i][sw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d11b66-cc21-4567-a8be-09730acb92b1",
   "metadata": {},
   "source": [
    "#### Inspection of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6e436c-3452-44f7-be91-79bc1deb8eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in NEGATIVE class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('EUR', 222),\n",
       " ('mn', 161),\n",
       " ('profit', 105),\n",
       " ('Finnish', 73),\n",
       " ('The', 72),\n",
       " ('sales', 69),\n",
       " ('year', 67),\n",
       " ('million', 64),\n",
       " ('net', 64),\n",
       " ('company', 64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common words in POSITIVE class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('EUR', 262),\n",
       " ('The', 186),\n",
       " ('said', 165),\n",
       " ('company', 163),\n",
       " ('year', 155),\n",
       " ('mn', 148),\n",
       " ('Finnish', 141),\n",
       " ('profit', 131),\n",
       " ('million', 113),\n",
       " ('sales', 113)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create histogram \n",
    "for c_i in categories:\n",
    "    print(f\"Most common words in {c_i.upper()} class:\")\n",
    "    display(vocab[c_i].most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb892344-e0b9-4e98-930a-f6e32dbdc065",
   "metadata": {},
   "source": [
    "#### Mututal information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a374c-4730-4ca6-9a5e-5ad9bb94132f",
   "metadata": {},
   "source": [
    "Mutual information can help us explain the differences between word distributions. Understanding the features that differentiate a certain category from another can prove very useful for interpretting differences between categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d80aac-6ce1-4b2f-b2da-374ea13876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of articles in each class, which we will need to calculate mutual information\n",
    "n_total = dict()\n",
    "for c_i in categories:\n",
    "    n_total[c_i] = len(train_text[c_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00532125-9f5e-4d78-b818-ccec005d1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 overall most informative features:\n",
      "\n",
      " ['decreased', 'fell', 'lower', 'mn', 'half', '2008', 'EUR', 'rose', 'compared', 'employees', 'profit', 'new', 'result', 'agreement', 'dropped', 'totalled', 'Operating', 'services', 'negotiations', 'declined', 'loss', 'staff', 'order', 'items', 'customers']\n"
     ]
    }
   ],
   "source": [
    "mi_list = sorted([(mutual_information(w, n_text, n_total), w) for w in set(vocab['negative']).union(set(vocab['positive']))], reverse=True)\n",
    "\n",
    "print('25 overall most informative features:\\n\\n', [w for mi, w in mi_list][:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879d0bc",
   "metadata": {},
   "source": [
    "## 3. Traditional sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d35271",
   "metadata": {},
   "source": [
    "### Loughran & McDonald classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446979d-60e4-4d7a-9597-d608a36170a0",
   "metadata": {},
   "source": [
    "Loughran & McDonald released their master dictionary in 2011 in conjunction with their paper “When is a Liability not a Liability? Textual Analysis, Dictionaries, and 10-Ks\". The dictionary lists a number of words and includes negative, positive, uncertainty, litigious, strong modal, weak modal, and constraining tags. \n",
    "\n",
    "There are several shortcomings to this simplistic approach:\n",
    "\n",
    "- **Some words don't appear in the dictionary (fall, rise, etc.)**\n",
    "- **Some words are negative/positive given the context they are written (profit, expenditure, etc.)**\n",
    "- **Simple counts of words don't necessarily infer the overall sentiment**\n",
    "    - *Hatred for football has always confused me; there are so many haters who attack the sport, but I have always loved it.* - 3 negative words and 1 positive word.\n",
    "\n",
    "\n",
    "We have taken the words that have a negative and positive tag for our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608eae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of negative words:  ['abandon', 'abandoned', 'abandoning', 'abandonment', 'abandonments']\n",
      "Some examples of positive words:  ['able', 'abundance', 'abundant', 'acclaimed', 'accomplish']\n"
     ]
    }
   ],
   "source": [
    "lmdict = np.load('data/LoughranMcDonald_dict.npy', allow_pickle='TRUE').item()\n",
    "print('Some examples of negative words: ', lmdict['Negative'][:5])\n",
    "print('Some examples of positive words: ', lmdict['Positive'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441f95e2-be4a-4263-96da-9dc07d68a45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able', 'abundance', 'abundant', 'acclaimed', 'accomplish']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmdict['Positive'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00495202-583a-4b11-8ede-7cfb61fd41db",
   "metadata": {},
   "source": [
    "Check to see if a word appears in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004cd19d-8fbe-4e5c-9538-2cfc0017d73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, fall is not in the Loughran & McDonald dictionary\n"
     ]
    }
   ],
   "source": [
    "word = 'fall'\n",
    "\n",
    "if word in lmdict['Negative']:\n",
    "    print(f'Yes, {word} is a Negative word in the Loughran & McDonald dictionary')\n",
    "elif word in lmdict['Positive']:\n",
    "    print(f'Yes, {word} is Positive word in the Loughran & McDonald dictionary')\n",
    "else:\n",
    "    print(f'No, {word} is not in the Loughran & McDonald dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f1465",
   "metadata": {},
   "source": [
    "Negation is another challenge that emerges using this approach. A techy fix is to check if the word is preceeded by a negating word in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d384c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "negate = [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\", \"ain't\", \"aren't\", \"can't\",\n",
    "          \"couldn't\", \"daren't\", \"didn't\", \"doesn't\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\",\n",
    "          \"neither\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\", \"neednt\", \"needn't\",\n",
    "          \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\", \"oughtnt\", \"shant\", \"shouldnt\", \"wasnt\",\n",
    "          \"werent\", \"oughtn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"without\", \"wont\", \"wouldnt\", \"won't\",\n",
    "          \"wouldn't\", \"rarely\", \"seldom\", \"despite\", \"no\", \"nobody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0377ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def negated(word):\n",
    "    \"\"\"\n",
    "    Determine if preceding word is a negation word\n",
    "    \"\"\"\n",
    "    if word.lower() in negate:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd91aa",
   "metadata": {},
   "source": [
    "This function counts the number of negative and positive words in a document and performs a negation check to switch the polarity of words that are preceeded by a word in the *negate* list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec407be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results with negation check:\n",
      "\n",
      "The # of positive words: 0\n",
      "The # of negative words: 6\n",
      "The list of found positive words: []\n",
      "The list of found negative words: ['worst', 'worse', 'recession', 'fears', 'recessions', 'decline']\n",
      "The overall classification is: negative\n"
     ]
    }
   ],
   "source": [
    "def tone_count_with_negation_check(dict, article):\n",
    "    \"\"\"\n",
    "    Count positive and negative words with negation check. Account for simple negation only for positive words.\n",
    "    Simple negation is taken to be observations of one of negate words occurring within three words\n",
    "    preceding a positive words.\n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    " \n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    " \n",
    "    input_words = re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', article.lower())\n",
    " \n",
    "    word_count = len(input_words)\n",
    " \n",
    "    for i in range(0, word_count):\n",
    "        if input_words[i] in dict['Negative']:\n",
    "            neg_count += 1\n",
    "            neg_words.append(input_words[i])\n",
    "        if input_words[i] in dict['Positive']:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                pos_count += 1\n",
    "                pos_words.append(input_words[i])\n",
    "                \n",
    "    sentiment_score = len(pos_words) - len(neg_words)\n",
    "    \n",
    "    if sentiment_score < 0:\n",
    "        classification = 'negative'\n",
    "    elif sentiment_score > 0:\n",
    "        classification = 'positive'\n",
    "    else:\n",
    "        classification = 'neutral'\n",
    " \n",
    "    results = [word_count, pos_count, neg_count, pos_words, neg_words, classification]\n",
    " \n",
    "    return results\n",
    " \n",
    "    \n",
    "# A sample output\n",
    "article = '''The stock market has had its worst start to a year in recent history and things could get \n",
    "             worse as recession fears loom. Since World War II there have been 13 recessions—defined as \n",
    "             two consecutive quarters of GDP decline–and there have been 3 in the 21st century (2001, 2008 and 2020), \n",
    "             according to the National Bureau of Economic Research. Some experts say another one could be on the way.'''\n",
    " \n",
    "sent_results = tone_count_with_negation_check(lmdict, article)\n",
    "\n",
    "print('The results with negation check:', end='\\n\\n')\n",
    "print('The # of positive words:', sent_results[1])\n",
    "print('The # of negative words:', sent_results[2])\n",
    "print('The list of found positive words:', sent_results[3])\n",
    "print('The list of found negative words:', sent_results[4])\n",
    "print('The overall classification is:', sent_results[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dee1da-6f30-491a-b31a-eb0e877862f7",
   "metadata": {},
   "source": [
    "Sometimes this technique can be successful, but there are many examples where it falls short. For example, when we use a clearly negative text that doesn't contain any words in the lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2cdaf7-6459-4ad0-92a9-00f377034870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results with negation check:\n",
      "\n",
      "The # of positive words: 0\n",
      "The # of negative words: 0\n",
      "The list of found positive words: []\n",
      "The list of found negative words: []\n",
      "The overall classification is: neutral\n"
     ]
    }
   ],
   "source": [
    "article = '''Pharmaceuticals group Orion Corp reported a fall in its third-quarter earnings that \n",
    "             were hit by larger expenditures on R&D and marketing'''\n",
    " \n",
    "sent_results = tone_count_with_negation_check(lmdict, article)\n",
    "\n",
    "print('The results with negation check:', end='\\n\\n')\n",
    "print('The # of positive words:', sent_results[1])\n",
    "print('The # of negative words:', sent_results[2])\n",
    "print('The list of found positive words:', sent_results[3])\n",
    "print('The list of found negative words:', sent_results[4])\n",
    "print('The overall classification is:', sent_results[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627da33-0944-4089-88aa-c499aecb0b7f",
   "metadata": {},
   "source": [
    "#### Performance on the Financial PhraseBank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15ff9a6c-393a-4d33-961f-8fcfeb9eaa49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = list(df['class'])\n",
    "predictions= list()\n",
    "\n",
    "for phrase, c_i in zip(df['text'], df['class']):\n",
    "    sent_results = tone_count_with_negation_check(lmdict, phrase)\n",
    "    classification = sent_results[5]\n",
    "    predictions.append(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "711dba89-2fea-4410-82ed-93db1b99740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We passed 1967 examples through the LM classifier \n",
      "\n",
      "There were 1231 NEUTRAL predictions\n",
      "There were 355 POSITIVE predictions\n",
      "There were 381 NEGATIVE predictions\n"
     ]
    }
   ],
   "source": [
    "neutral_count = predictions.count('neutral')\n",
    "positive_count = predictions.count('positive')\n",
    "negative_count = predictions.count('negative')\n",
    "\n",
    "print(f'We passed {len(predictions)} examples through the LM classifier \\n')\n",
    "print(f'There were {neutral_count} NEUTRAL predictions')\n",
    "print(f'There were {positive_count} POSITIVE predictions')\n",
    "print(f'There were {negative_count} NEGATIVE predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecba44f5-cbe7-4ab8-b473-609628f1f885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.672     0.424     0.520       604\n",
      "     neutral      0.000     0.000     0.000         0\n",
      "    positive      0.961     0.250     0.397      1363\n",
      "\n",
      "    accuracy                          0.304      1967\n",
      "   macro avg      0.544     0.225     0.306      1967\n",
      "weighted avg      0.872     0.304     0.435      1967\n",
      "\n",
      "f1 score :  0.30559005966486036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, predictions, digits=3))\n",
    "print('f1 score : ',f1_score(labels, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3033173-1b0d-42b9-9a94-5e46ded9b4ef",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589ae9f-842e-4b6e-89b7-2bd147d759f0",
   "metadata": {},
   "source": [
    "A NB classifier improves upon the lexicon technique explored above as it utilises the individual contribution of each word in the text. The fundamental training goal of a NB classifier is to calculate the individual probability of a word appearing in a particular class, $P(w|c_i)$, and summing the log probability of each word to discern $P(d|c_i)$. \n",
    "\n",
    "There are some assumptions and training details in our model:\n",
    "- Add-one smoothing - assume that all words appear once in each class so that one can calculate the probability for a word appearing.\n",
    "    - Large oversimplification but it is necessary for both classes to have the same support.\n",
    "- Remove all stop words - probability distribution of stop words doesn't neccessarily discern sentiment classification.\n",
    "    - she, he, it, so, I, etc. \n",
    "    \n",
    "##### Advantages and disadvatanges:\n",
    "    \n",
    "<font color='green'>$\\checkmark$</font>   Granular feature set \\\n",
    "<font color='green'>$\\checkmark$</font>   Can also include bigrams, trigrams, emojis etc. for improved performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77298ce7-dc82-42a1-9103-240a38a4e9cb",
   "metadata": {},
   "source": [
    "#### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a95616-a1c6-407b-85c2-c82cec38e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with additive smoothing\n",
    "# Define function to get P(w|c_i), class-conditional propbabilities for w\n",
    "\n",
    "def naive_bayes_additive_smoothing(vocab, categories, smoothing_alpha):\n",
    "    \n",
    "    # Calculate unsmoothed probabilities\n",
    "    probabilities = dict()\n",
    "    \n",
    "    for c_i in categories:\n",
    "        \n",
    "        probabilities[c_i] = dict()\n",
    "        \n",
    "        # First, consider all words that are in the vocab for either class\n",
    "        for word in set(vocab[\"hateful\"]).union(set(vocab[\"non-hateful\"])):\n",
    "            # If they do exist in the current class c_i, store their count --> 1st order model\n",
    "            if vocab[c_i][word]>0:\n",
    "                probabilities[c_i][word] = vocab[c_i][word]\n",
    "            # If not, set their count to be the smoothing parameter (rather than excluding them, as we did for no smoothing) --> backoff to 0th order model\n",
    "            else:\n",
    "                probabilities[c_i][word] = smoothing_alpha\n",
    "        \n",
    "        # Second, we take the sum of counts of words in this new dict\n",
    "        total = sum(probabilities[c_i].values())\n",
    "        \n",
    "        # Last, we turn the counts for each word into probabilities by dividing them by that sum\n",
    "        probabilities[c_i] = {word: probabilities[c_i][word] / total for word in probabilities[c_i]}\n",
    "    \n",
    "    return probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ef887-ee24-4a55-b2c2-379affc1f327",
   "metadata": {},
   "source": [
    "Estimate the probability of the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9d0695f-2de6-465a-8bf6-ca7e95ce8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate P(c_i), the probability of class c_i, based on the class distribution in the test set\n",
    "prob_class = dict()\n",
    "for c_i in categories:\n",
    "    prob_class[c_i] = train_text[c_i].shape[0]/(train_text[\"negative\"].shape[0]+train_text[\"positive\"].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4848084-5a79-4d05-afff-827da94b4f18",
   "metadata": {},
   "source": [
    "Retrieve the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "993c87f6-c92a-43b2-9b4d-ecd94c775cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_predictions(categories, test_tweets, probabilities, prob_class):\n",
    "\n",
    "    # Initialize lists for storing ground truth labels and predictions\n",
    "    labels = list()\n",
    "    predictions = list()\n",
    "\n",
    "    # Loop over categories\n",
    "    for c_i in categories:\n",
    "\n",
    "        # Loop over test tweets\n",
    "        for tweet in test_tweets[c_i]:\n",
    "            #print(c_i,tweet)\n",
    "\n",
    "            # Store ground truth\n",
    "            labels.append(c_i)\n",
    "\n",
    "            # For each post, calculate scores for each of the two categories\n",
    "            scores = {'negative': 0, 'positive': 0}\n",
    "            for word in tweet:\n",
    "                if word in probabilities[c_i]:\n",
    "                    scores[\"negative\"] += np.log(probabilities[\"negative\"][word])\n",
    "                    scores[\"positive\"] += np.log(probabilities[\"positive\"][word])\n",
    "\n",
    "            # Class imbalance\n",
    "            scores[\"negative\"] = scores[\"negative\"]+np.log(prob_class[\"negative\"])\n",
    "            scores[\"positive\"] = scores[\"positive\"]+np.log(prob_class[\"positive\"])\n",
    "\n",
    "            # Use higher score for prediction\n",
    "            predictions.append(max(scores.items(), key=operator.itemgetter(1))[0])\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65c59178-f511-4404-9c29-1e9e1dbda016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.000     0.000     0.000        91\n",
      "    positive      0.692     1.000     0.818       204\n",
      "\n",
      "    accuracy                          0.692       295\n",
      "   macro avg      0.346     0.500     0.409       295\n",
      "weighted avg      0.478     0.692     0.565       295\n",
      "\n",
      "f1 score :  0.4088176352705411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "probs = naive_bayes_additive_smoothing(vocab, categories, smoothing_alpha=0.1)\n",
    "\n",
    "# Get predictions on dev set\n",
    "labels, predictions = get_nb_predictions(categories, dev_text, probs, prob_class)\n",
    "\n",
    "# Calculate and store macro F1 on test set\n",
    "print(classification_report(labels, predictions, digits=3))\n",
    "print('f1 score : ',f1_score(labels, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a12738db-5639-45d5-b6b7-124c6b7a1553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(pd.Series(labels).replace({'positive':0,'negative':1}), pd.Series(predictions).replace({'positive':0,'negative':1})),\n",
    "            annot =confusion_matrix(pd.Series(labels).replace({'positive':0,'negative':1}), pd.Series(predictions).replace({'positive':0,'negative':1})) ,\n",
    "            fmt='g',cmap='Blues',xticklabels=['Positive','Negative'], yticklabels=['Positive','Negative'])#,labels = ['1','-1','0']\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a1719-18c7-46fe-8487-37cbf180b3ab",
   "metadata": {},
   "source": [
    "## 3. BERT classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03516dc1-abee-498f-a856-804b47983c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drago\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import all dependencies \n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# huggingface transformers --> see on the website \n",
    "from transformers import AutoTokenizer,logging\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,BertForMaskedLM,AutoTokenizer\n",
    "from transformers import  TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from transformers import AutoConfig\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebd00440-17d2-4f02-bc0a-5e07b37cffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91227355-8b5c-4bb6-bcc8-2485bdb4949c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the dataset from huggingfaces' dataset repository\n",
    "#fin_dataset = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
    "#df = pd.DataFrame(fin_dataset['train']) # send  it to a pandas dataframe\n",
    "\n",
    "# If you are having issues running the code above on Windows, don't worry this is a known Huggingface error-\n",
    "# Please use the code below which wille import the data we were planning to use from a .txt file\n",
    "\n",
    "#origin of this data : data/FinancialPhraseBanl-v1.0\n",
    "\n",
    "df = pd.read_csv('data\\\\FinancialPhraseBank-v1.0\\\\Sentences_50Agree.txt',\n",
    "            encoding = 'ISO-8859-1',on_bad_lines='skip',sep = '.@')\n",
    "df.columns = ['sentence','label']\n",
    "df['label'] = df['label'].replace(to_replace=({'neutral':2,'positive':0,'negative':1}))\n",
    "df['label']= df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b653abe5-5242-4ff3-b0c7-0595e6f4b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the task comparable to the Bayesian classifier above we will also drop the neutral class \n",
    "\n",
    "df = df[df['label']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "228a2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "395ff2f9-a731-40c1-870a-55b23cbfb18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.692933\n",
       "1    0.307067\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22345d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "675e1335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is our input sentence : \n",
      " Hi my name is BERT and I am overjoyed  to meet you ! \n",
      "\n",
      "These are the outputs of the tokenizer:\n",
      "\n",
      "{'input_ids': tensor([[  101,  8790,  1139,  1271,  1110,   139,  9637,  1942,  1105,   146,\n",
      "          1821,  1166, 18734,  1174,  1106,  2283,  1128,   106,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "\n",
      "These inputs correspond to the original sentence with separation and padding thrown in :\n",
      "\n",
      "['[CLS] Hi my name is BERT and I am overjoyed to meet you! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "#how does the tokenizer work ? \n",
    "print('\\nThis is our input sentence : \\n Hi my name is BERT and I am overjoyed  to meet you ! \\n')\n",
    "\n",
    "out = tokenizer(['Hi my name is BERT and I am overjoyed  to meet you ! '],\n",
    "          max_length=64,padding=\"max_length\", truncation=True,return_tensors='pt')\n",
    "print('These are the outputs of the tokenizer:\\n')\n",
    "print(out)\n",
    "\n",
    "print('\\nThese inputs correspond to the original sentence with separation and padding thrown in :\\n')\n",
    "print([tokenizer.decode(i) for i in out['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ed749a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is our model : \n",
      "\n",
      "\n",
      " First layer shape (vocabulary size) : \n",
      "  torch.Size([28996, 768]) \n",
      " Number of self attention heads:  12 \n",
      " Last layer shape (prediction task output shape) : \n",
      "  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Now that we covered  the tokenizer lets introduce the other building block : the model \n",
    "\n",
    "print('this is our model : \\n')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased')\n",
    "layers = [i for i in model.parameters()]\n",
    "print('\\n First layer shape (vocabulary size) : \\n ',layers[0].shape,\n",
    "      '\\n Number of self attention heads: ',len([i.shape  for i in layers if (i.shape==torch.Size([3072])) ]),\n",
    "'\\n Last layer shape (prediction task output shape) : \\n ',layers[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c745e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our forward propagation syntax. \n",
      " We feed in a tokenized text and receive the \n",
      " predicted  logits over the 2 classes : \n",
      "\n",
      "tensor([[0.0024, 0.1746]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# basic forward propagation of our BERT model \n",
    "print('This is our forward propagation syntax. \\n We feed in a tokenized text and receive the \\n predicted  logits over the 2 classes : \\n')\n",
    "model_output = model.forward(**out)\n",
    "print(model_output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebec1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with BERT hands-on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baf53dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  define tokenizer & model \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# turn the configuration for a 2 sentiment classification task\n",
    "config = AutoConfig.from_pretrained('bert-base-cased')\n",
    "config.num_labels = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "966ed0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=123)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b38988d-5ed7-4eaa-9c28-6c6ddef1ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.688953\n",
      "1    0.311047\n",
      "Name: label, dtype: float64 \n",
      " 0    0.738983\n",
      "1    0.261017\n",
      "Name: label, dtype: float64 \n",
      " 0    0.665541\n",
      "1    0.334459\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.label.value_counts(normalize=True),'\\n',\n",
    "test.label.value_counts(normalize=True),'\\n',\n",
    "val.label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3399a3e-ba2d-4e27-bffd-1bc533f63b45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining a dataset class to interact with the Huggingface Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "423f2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Dataset object to put our data in\n",
    "\n",
    "\n",
    "class BERTTutorialDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Special dataset class built on top of the torch Dataset class\n",
    "    useful to have memory efficient dataloading tokenization batching and trainning.\n",
    "    \n",
    "    Huggingface can use these types of dataset as inputs and run all trainning/prediction on them. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_data, sentiment_targets, tokenizer, max_len):\n",
    "        \"\"\"\n",
    "        Basic generator function for the class.\n",
    "        -----------------\n",
    "        input_data : array\n",
    "            Numpy array of string  input text to use for downstream task \n",
    "        sentiment_targets : \n",
    "            Numpy array of integers indexed in  the pytorch style of [0,C-1] with C being the total number of classes\n",
    "            In our example this means the target sentiments should range from 0 to 2. \n",
    "        tokenizer  : Huggingface tokenizer \n",
    "            The huggingface tokenizer to use\n",
    "        max_len : \n",
    "            The truncation length of the tokenizer \n",
    "        -------------------\n",
    "        \n",
    "        Returns : \n",
    "        \n",
    "            Tokenized text with inputs, attentions and labels, ready for the Training script. \n",
    "        \"\"\"\n",
    "        self.input_data = input_data\n",
    "        self.sentiment_targets = sentiment_targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Function required by torch huggingface to batch efficiently\n",
    "        \"\"\"\n",
    "        return len(self.input_data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.input_data[item])\n",
    "        target = self.sentiment_targets[item]\n",
    "        # only difference with the previuous tokenization step is the encode-plus for special tokens\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding='max_length',\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "          truncation = True\n",
    "        )\n",
    "        return {\n",
    "         # 'text': text,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'labels': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a52df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our train-val-test datasets\n",
    "MAX_LEN = 128\n",
    "train_ds = BERTTutorialDataset(\n",
    "    input_data=train['sentence'].to_numpy(),\n",
    "        sentiment_targets=train['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "val_ds = BERTTutorialDataset(\n",
    "    input_data=val['sentence'].to_numpy(),\n",
    "        sentiment_targets=val['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "test_ds = BERTTutorialDataset(\n",
    "    input_data=test['sentence'].to_numpy(),\n",
    "        sentiment_targets=test['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfc2a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some accuracy measure ( helpful for the early stopping )\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracies and losses for the validation from the predicted outputs\n",
    "    This is neccessary for the early stopping. \n",
    "    \"\"\"\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb9410-4e7e-4535-ba5d-da3dc009bfa2",
   "metadata": {},
   "source": [
    "## Defining the trainning arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71b300ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainning arguments \n",
    "training_args = TrainingArguments(\n",
    "                                #Parameters to manage the output, saving & storing of the model you train \n",
    "                                output_dir='BERT_TUTORIAL_MODEL', overwrite_output_dir=True, evaluation_strategy=\"steps\",\n",
    "                                  save_total_limit=5, save_steps=50,load_best_model_at_end = True,\n",
    "                                # Parameters determining how fast & for how long & against what metric your model learns\n",
    "                                  num_train_epochs=50, weight_decay=1e-8,learning_rate=1e-5,\n",
    "                                  eval_steps=50,metric_for_best_model='f1', per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
    "                                # Parameters to speed up computation \n",
    "                                 no_cuda=False, # run on gpu if you have it \n",
    "                                 fp16=True, # half point precision\n",
    "                                gradient_accumulation_steps=4) # gradient acumulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15230a-2b50-45fe-836b-bc216dda9cd1",
   "metadata": {},
   "source": [
    "### Lauching the training process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62f06c-db53-4948-b6e3-ce68459c8658",
   "metadata": {},
   "source": [
    "Here you can chosse whether :\n",
    "* to launch the training process to finetune the final layer of the BERT classifier on the training data\n",
    "* to use the model we have finetuned before this tutorial on the same data --> we will do this in the interst of time but feel free \n",
    "    to run it  while we explain the rest or over lunch and ask questions !"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fec899ab-8f58-4645-ab22-ab291a122861",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# If you want to reuse the trained model we fine-tuned for this tutorial it is simple, please run : \n",
    "model = AutoModelForSequenceClassification.from_pretrained('BERT_TUTORIAL_MODEL/checkpoint-700')\n",
    "\n",
    "# instatiate Trainer class\n",
    "trainer = Trainer(\n",
    "    # Which model are you trainning and how\n",
    "    model =model, args=training_args,\n",
    "    # What data are you uing to train and validate\n",
    "    train_dataset=train_ds, eval_dataset=val_ds,\n",
    "    # How are you validating and when do you stop training\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6bc1367-d8b6-4e65-bfcb-a8bc80eb8726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 1376\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1050\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-50\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-50\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6209684014320374, 'eval_accuracy': 0.6655405405405406, 'eval_precision': 0.3327702702702703, 'eval_recall': 0.5, 'eval_f1': 0.3995943204868154, 'eval_runtime': 2.7526, 'eval_samples_per_second': 107.534, 'eval_steps_per_second': 6.902, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-50\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-100\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-100\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5816304087638855, 'eval_accuracy': 0.706081081081081, 'eval_precision': 0.6645385587863464, 'eval_recall': 0.6334666461570015, 'eval_f1': 0.6397666708632339, 'eval_runtime': 1.6662, 'eval_samples_per_second': 177.653, 'eval_steps_per_second': 11.403, 'epoch': 4.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-150\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-150\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5405267477035522, 'eval_accuracy': 0.7364864864864865, 'eval_precision': 0.7110157367668097, 'eval_recall': 0.6588217197354254, 'eval_f1': 0.6685615848406545, 'eval_runtime': 1.143, 'eval_samples_per_second': 258.97, 'eval_steps_per_second': 16.623, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-150\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-200\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-200\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5773450136184692, 'eval_accuracy': 0.7601351351351351, 'eval_precision': 0.7680487804878049, 'eval_recall': 0.6690509152438087, 'eval_f1': 0.681609526262366, 'eval_runtime': 1.1093, 'eval_samples_per_second': 266.832, 'eval_steps_per_second': 17.128, 'epoch': 9.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-200\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-250\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-250\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49068260192871094, 'eval_accuracy': 0.7837837837837838, 'eval_precision': 0.7633347431740214, 'eval_recall': 0.7873147720863457, 'eval_f1': 0.7693693693693693, 'eval_runtime': 2.4385, 'eval_samples_per_second': 121.384, 'eval_steps_per_second': 7.792, 'epoch': 11.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-250\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-300\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-300\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5299763083457947, 'eval_accuracy': 0.7668918918918919, 'eval_precision': 0.7568794716565768, 'eval_recall': 0.7871865866789725, 'eval_f1': 0.7572472811552862, 'eval_runtime': 1.6317, 'eval_samples_per_second': 181.408, 'eval_steps_per_second': 11.644, 'epoch': 14.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-300\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-350\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-350\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4856829345226288, 'eval_accuracy': 0.8378378378378378, 'eval_precision': 0.8218172071830608, 'eval_recall': 0.8078244372660617, 'eval_f1': 0.8139827179890025, 'eval_runtime': 1.7936, 'eval_samples_per_second': 165.028, 'eval_steps_per_second': 10.593, 'epoch': 16.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-350\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-400\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-400\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5287584662437439, 'eval_accuracy': 0.8277027027027027, 'eval_precision': 0.8329329962073324, 'eval_recall': 0.7700610162539097, 'eval_f1': 0.7888287380922405, 'eval_runtime': 1.8607, 'eval_samples_per_second': 159.084, 'eval_steps_per_second': 10.211, 'epoch': 19.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-950] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-450\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-450\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5743995308876038, 'eval_accuracy': 0.8277027027027027, 'eval_precision': 0.8405138339920949, 'eval_recall': 0.7650361482848793, 'eval_f1': 0.7857355758995104, 'eval_runtime': 1.8417, 'eval_samples_per_second': 160.724, 'eval_steps_per_second': 10.317, 'epoch': 21.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3552, 'learning_rate': 5.2380952380952384e-06, 'epoch': 23.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-500\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4871998429298401, 'eval_accuracy': 0.8445945945945946, 'eval_precision': 0.8347923055478115, 'eval_recall': 0.8078757114290109, 'eval_f1': 0.8186274509803921, 'eval_runtime': 0.7625, 'eval_samples_per_second': 388.193, 'eval_steps_per_second': 24.918, 'epoch': 23.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-1050] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-550\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-550\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5568724870681763, 'eval_accuracy': 0.8378378378378378, 'eval_precision': 0.8356757397853288, 'eval_recall': 0.7902373993744553, 'eval_f1': 0.8059440559440559, 'eval_runtime': 0.7581, 'eval_samples_per_second': 390.427, 'eval_steps_per_second': 25.061, 'epoch': 26.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-600\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-600\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5247085690498352, 'eval_accuracy': 0.8378378378378378, 'eval_precision': 0.8247813892097013, 'eval_recall': 0.8027995692970312, 'eval_f1': 0.811854441442873, 'eval_runtime': 0.7583, 'eval_samples_per_second': 390.364, 'eval_steps_per_second': 25.057, 'epoch': 28.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-650\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-650\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5522922873497009, 'eval_accuracy': 0.8412162162162162, 'eval_precision': 0.8198757763975155, 'eval_recall': 0.8379992821617187, 'eval_f1': 0.8269458023908148, 'eval_runtime': 0.8923, 'eval_samples_per_second': 331.735, 'eval_steps_per_second': 21.294, 'epoch': 30.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-150] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-700\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-700\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5568892359733582, 'eval_accuracy': 0.8412162162162162, 'eval_precision': 0.829734219269103, 'eval_recall': 0.805337640363021, 'eval_f1': 0.8152334152334153, 'eval_runtime': 0.7613, 'eval_samples_per_second': 388.829, 'eval_steps_per_second': 24.959, 'epoch': 33.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-750\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-750\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.55194491147995, 'eval_accuracy': 0.8513513513513513, 'eval_precision': 0.8316816741284773, 'eval_recall': 0.8380761934061427, 'eval_f1': 0.8346788525006347, 'eval_runtime': 0.7546, 'eval_samples_per_second': 392.239, 'eval_steps_per_second': 25.178, 'epoch': 35.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-250] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-800\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-800\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6020705103874207, 'eval_accuracy': 0.8513513513513513, 'eval_precision': 0.847660063163939, 'eval_recall': 0.8104394195764755, 'eval_f1': 0.8243797195253506, 'eval_runtime': 0.7603, 'eval_samples_per_second': 389.324, 'eval_steps_per_second': 24.99, 'epoch': 38.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-850\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-850\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6523467302322388, 'eval_accuracy': 0.8581081081081081, 'eval_precision': 0.8729264475743349, 'eval_recall': 0.8054658257703944, 'eval_f1': 0.8267075550599388, 'eval_runtime': 0.7602, 'eval_samples_per_second': 389.35, 'eval_steps_per_second': 24.992, 'epoch': 40.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-350] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-900\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-900\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5957226753234863, 'eval_accuracy': 0.8445945945945946, 'eval_precision': 0.8284337094125749, 'eval_recall': 0.8179254473670717, 'eval_f1': 0.8227083333333334, 'eval_runtime': 0.8029, 'eval_samples_per_second': 368.647, 'eval_steps_per_second': 23.663, 'epoch': 42.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-950\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-950\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6062391400337219, 'eval_accuracy': 0.8445945945945946, 'eval_precision': 0.8329208601440907, 'eval_recall': 0.8103881454135261, 'eval_f1': 0.8196938397160867, 'eval_runtime': 0.7583, 'eval_samples_per_second': 390.329, 'eval_steps_per_second': 25.055, 'epoch': 45.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-450] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 296\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0787, 'learning_rate': 4.7619047619047623e-07, 'epoch': 47.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to BERT_TUTORIAL_MODEL\\checkpoint-1000\n",
      "Configuration saved in BERT_TUTORIAL_MODEL\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6124706864356995, 'eval_accuracy': 0.8445945945945946, 'eval_precision': 0.8272846294841582, 'eval_recall': 0.8204378813515869, 'eval_f1': 0.823654354245454, 'eval_runtime': 0.7944, 'eval_samples_per_second': 372.612, 'eval_steps_per_second': 23.918, 'epoch': 47.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in BERT_TUTORIAL_MODEL\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [BERT_TUTORIAL_MODEL\\checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from BERT_TUTORIAL_MODEL\\checkpoint-750 (score: 0.8346788525006347).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 909.1416, 'train_samples_per_second': 75.676, 'train_steps_per_second': 1.155, 'train_loss': 0.21693751525878907, 'epoch': 47.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.21693751525878907, metrics={'train_runtime': 909.1416, 'train_samples_per_second': 75.676, 'train_steps_per_second': 1.155, 'train_loss': 0.21693751525878907, 'epoch': 47.6})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to run the trainer run the code below ( it takes about 12 minutes )\n",
    "# Its as easy as creating the trainer and runnning trainer.train()\n",
    "\n",
    "logging.set_verbosity(20) #--> Set the verbosity of the model to see the progress bar on the training \n",
    "# instatiate Trainer class\n",
    "trainer = Trainer(\n",
    "    # Which model are you trainning and how\n",
    "    model =model, args=training_args,\n",
    "    # What data are you uing to train and validate\n",
    "    train_dataset=train_ds, eval_dataset=val_ds,\n",
    "    # How are you validating and when do you stop training\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# launch training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "351f29b6-25b8-41f6-b2d7-c2f4cda568bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5963194370269775, 'eval_accuracy': 0.847457627118644, 'eval_precision': 0.8006126188022443, 'eval_recall': 0.8127904205885857, 'eval_f1': 0.8062863897036291, 'eval_runtime': 2.6172, 'eval_samples_per_second': 112.718, 'eval_steps_per_second': 7.26, 'epoch': 47.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5963194370269775,\n",
       " 'eval_accuracy': 0.847457627118644,\n",
       " 'eval_precision': 0.8006126188022443,\n",
       " 'eval_recall': 0.8127904205885857,\n",
       " 'eval_f1': 0.8062863897036291,\n",
       " 'eval_runtime': 2.6172,\n",
       " 'eval_samples_per_second': 112.718,\n",
       " 'eval_steps_per_second': 7.26,\n",
       " 'epoch': 47.6}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e692afc7-fd72-4520-aa87-047c4869ce0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 295\n",
      "  Batch size = 16\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you want to evaluate the trainer run the code below\n",
    "\n",
    "predictions = trainer.predict(test_ds)\n",
    "output = np.argmax(predictions.predictions,1)\n",
    "sns.heatmap(confusion_matrix(test.label.values,output),\n",
    "            annot =confusion_matrix(test.label.values,output) ,\n",
    "            fmt='g',cmap='Blues',xticklabels=['Positive','Negative'], yticklabels=['Positive','Negative'])#,labels = ['1','-1','0']\n",
    "plt.ylabel(\"Predicted class\")\n",
    "plt.xlabel(\"Actual class\")\n",
    "plt.show()\n",
    "#del predictions #--> We delete the predictions as we don't want to occupy too much gpu space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ae2ea59-04e2-429b-b2f7-432d989f0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged 'eval_f1': 0.7565478000260608 --> That is about double what the previous model gave us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cbfe5c9-5e8d-44bc-a18b-9f63d530b85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deleting all our objects to save GPU space\n",
    "#del model\n",
    "#del trainer\n",
    "#del train_ds\n",
    "#del val_ds\n",
    "#del test_ds\n",
    "#del tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81bd1d3-d889-44e2-83a4-a465b0dfb443",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Masked Language Modelling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33d9d861-f228-4161-bfab-c51bdcdc49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will not be running the code below as it would take a long time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c2200-7216-4817-ac16-d2edc0b0862d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "# Import the model & tokenizer\n",
    "\n",
    "model_to_pretrain = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "tokenizer_for_pretraining = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# tokenize the inputs of the text \n",
    "inputs_for_pretraining = tokenizer_for_pretraining(df.sentence.tolist(), return_tensors='pt', max_length=32, truncation=True, padding='max_length')\n",
    "inputs_for_pretraining['labels'] = inputs.input_ids.detach().clone()\n",
    "\n",
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "random_mask = torch.rand(inputs_for_pretraining.input_ids.shape)\n",
    "\n",
    "# create mask array --> we hide 15% of the inputs for the masked language modelling task  \n",
    "mask_arr = (random_mask < 0.15) * (inputs_for_pretraining.input_ids != 101) * \\\n",
    "           (inputs_for_pretraining.input_ids != 102) * (inputs_for_pretraining.input_ids != 0)\n",
    "\n",
    "selection = []\n",
    "\n",
    "for i in range(inputs_for_pretraining.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "for i in range(inputs_for_pretraining.input_ids.shape[0]):\n",
    "    inputs_for_pretraining.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    \n",
    "class TUTORIALDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This is also a Dataset class as the Dataset class before \n",
    "    \"\"\"\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "    \n",
    "dataset = TUTORIALDataset(inputs_for_pretraining)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Move model to device\n",
    "model_to_pretrain.to(device)\n",
    "# launch model training\n",
    "model_to_pretrain.train()\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='out',\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2 #only 2 train epochs --> this is a safety check as this is a toy example, running a proper script with hyperparameters tuned for learning would take upwards of 10 hours ! \n",
    ")\n",
    "\n",
    "MLM_trainer = Trainer(\n",
    "    model=model_to_pretrain,\n",
    "    args=args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "MLM_trainer.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bc5b6-81fd-4b69-ad92-60f6626fdbb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abe53179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import SequenceClassificationExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49975436-7777-4aff-8c59-df929efd047b",
   "metadata": {},
   "source": [
    "To visualise which words in each phrase are the most important for the prediction we will use the python package transformers_interpret "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9239482-bcad-465d-bba0-44b12470dc24",
   "metadata": {},
   "source": [
    "We will compare explainability on : \n",
    "* Bert finetuned on textattack --> for a convenient baseline\n",
    "* Bert finetuned on the financial phrasebank\n",
    "* Finbert --> Bert pretrained and finetuned on the financial phrasebank \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cd84b54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/ProsusAI/finbert/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\2120f4f96b5830e5a91fe94d242471b0133b0976c8d6e081594ab837ac5f17bc.ef97278c578016c8bb785f15296476b12eae86423097fed78719d1c8197a3430\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"ProsusAI/finbert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/ProsusAI/finbert/resolve/main/pytorch_model.bin from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\b3ba5be9f12905cef8d1d18af435dfd568d75466fae4a117a4f20ed5faadd3e3.8764ec40d33a40810fe5d2c1e864945dcf7affafd797ed8ef1b71392bfcf8562\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ProsusAI/finbert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/ProsusAI/finbert/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\2120f4f96b5830e5a91fe94d242471b0133b0976c8d6e081594ab837ac5f17bc.ef97278c578016c8bb785f15296476b12eae86423097fed78719d1c8197a3430\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"ProsusAI/finbert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/ProsusAI/finbert/resolve/main/vocab.txt from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\a5b1a5451c9cf1702eec1072ac325d4af10e675a654628eab453b8cba2c6b111.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/ProsusAI/finbert/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/ProsusAI/finbert/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/ProsusAI/finbert/resolve/main/special_tokens_map.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\4c21e8896b03f68c2e028133cf579267c62aba9de03a704a0845704e58eefe9e.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/ProsusAI/finbert/resolve/main/tokenizer_config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\e3709a60694f45adca209a405cc69ce2b5d47b1cae60696ed9a901426be8c43d.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
      "loading configuration file https://huggingface.co/ProsusAI/finbert/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\2120f4f96b5830e5a91fe94d242471b0133b0976c8d6e081594ab837ac5f17bc.ef97278c578016c8bb785f15296476b12eae86423097fed78719d1c8197a3430\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"ProsusAI/finbert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/ProsusAI/finbert/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\2120f4f96b5830e5a91fe94d242471b0133b0976c8d6e081594ab837ac5f17bc.ef97278c578016c8bb785f15296476b12eae86423097fed78719d1c8197a3430\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"ProsusAI/finbert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\293ab95645c102b941dee443ccf73fb9b5b5a9706b9893f09b5f1941b1bd0c8b.32da30c4245b376f0c4fd55aaf1c536c5ef13f10c248390e0311fcb4ca48f475\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"textattack/bert-base-uncased-SST-2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/pytorch_model.bin from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\a7511de9d84e49d590d1debe392368a67a14cccc4bde4f72d766705702d2edd9.495764b52432aefa3c4d3988b595993be3f3d1e407c2cb9f3d5eb4ff4e886d1d\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at textattack/bert-base-uncased-SST-2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\293ab95645c102b941dee443ccf73fb9b5b5a9706b9893f09b5f1941b1bd0c8b.32da30c4245b376f0c4fd55aaf1c536c5ef13f10c248390e0311fcb4ca48f475\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"textattack/bert-base-uncased-SST-2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/vocab.txt from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\9c8dda35c85d8852699ae2daa805d96a9e139eb93ab411edd3e7de9ff27c131f.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/special_tokens_map.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\c7c9b9c5d8bab3ba2ddaa08b138aa385f9790f30e8dce3bfe47e3f10bd97f4ad.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/tokenizer_config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\b0a5f8537502519294ee167d172bf5daff91c9277ffc722e9f46d6c8c05d2f55.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
      "loading configuration file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\293ab95645c102b941dee443ccf73fb9b5b5a9706b9893f09b5f1941b1bd0c8b.32da30c4245b376f0c4fd55aaf1c536c5ef13f10c248390e0311fcb4ca48f475\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"textattack/bert-base-uncased-SST-2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/textattack/bert-base-uncased-SST-2/resolve/main/config.json from cache at C:\\Users\\drago/.cache\\huggingface\\transformers\\293ab95645c102b941dee443ccf73fb9b5b5a9706b9893f09b5f1941b1bd0c8b.32da30c4245b376f0c4fd55aaf1c536c5ef13f10c248390e0311fcb4ca48f475\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"textattack/bert-base-uncased-SST-2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin_model_name = \"ProsusAI/finbert\"\n",
    "model_name = \"textattack/bert-base-uncased-SST-2\"\n",
    "\n",
    "\n",
    "fin_model = AutoModelForSequenceClassification.from_pretrained(fin_model_name)\n",
    "fin_tokenizer = AutoTokenizer.from_pretrained(fin_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76a1f016-b6c1-4a8c-8354-383518d8bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desktop/Python/OxfordManInstituteNLPConference/BERT_TUTORIAL_MODEL/checkpoint-750'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Desktop/Python/OxfordManInstituteNLPConference/BERT_TUTORIAL_MODEL/checkpoint-750'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b45eb39-591f-4386-af94-4e56fd55ac70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file BERT_TUTORIAL_MODEL/checkpoint-750\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BERT_TUTORIAL_MODEL/checkpoint-750\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file BERT_TUTORIAL_MODEL/checkpoint-750\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BERT_TUTORIAL_MODEL/checkpoint-750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('BERT_TUTORIAL_MODEL/checkpoint-750')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be06563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With both the model and tokenizer initialized we are now able to get explanations on an example text.\n",
    "cls_explainer = SequenceClassificationExplainer(model,\n",
    "                                                tokenizer)\n",
    "\n",
    "fin_cls_explainer = SequenceClassificationExplainer(fin_model,\n",
    "                                                    fin_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979f669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ff99d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(\"Pharmaceuticals group Orion Corp reported a fall in its third-quarter earnings that were hit by larger expenditures on R&D and marketing\")\n",
    "word_attributions = fin_cls_explainer(\"Pharmaceuticals group Orion Corp reported a fall in its third-quarter earnings that were hit by larger expenditures on R&D and marketing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecaf21c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_1'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_explainer.predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a6dda98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.87)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>0.78</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pharmaceuticals                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> group                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> orion                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> corp                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reported                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fall                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> third                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quarter                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> earnings                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hit                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> larger                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> expenditures                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> r                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> &                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> marketing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_vis = cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "050d7ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>negative (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>2.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pharmaceuticals                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> group                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> orion                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> corp                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reported                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fall                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> third                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quarter                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> earnings                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> were                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hit                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> larger                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> expenditures                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> r                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> &                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> d                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> marketing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fin_bert_vis = fin_cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29c295-4bea-40b7-8c84-eba16c9a05e2",
   "metadata": {},
   "source": [
    "# In summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35c27e-2789-441a-bd39-aae7b1fa4478",
   "metadata": {},
   "source": [
    "| **Model name**        | **Loughram McDonald** | **Naive Bayes** | **Bert** | **FinBert** |\n",
    "|-----------------------|-----------------------|-----------------|----------|-------------|\n",
    "| **Averaged F1 Score** | 0.2544                | 0.3954          | 0.7564   |    0.8866   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada06b62-cfd5-4eb0-a581-ef7c334163c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
